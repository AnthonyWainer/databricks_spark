{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"test\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header =Row(\"ID\", \"Name\", \"gender\", \"Salary\", \"Department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = spark.sparkContext.parallelize([\n",
    "    header(1, \"Deva\", \"Male\", 5000, \"Sales\"), \n",
    "    header(2, \"Jugnu\", \"Female\", 6000, \"HR\"), \n",
    "    header(3, \"Kavita\", \"Female\", 7500, \"IT\"), \n",
    "    header(4, \"Vikram\", \"Male\", 6500, \"Marketing\"), \n",
    "    header(5, \"Shabana\", \"Female\", 5500, \"Finance\"), \n",
    "    header(6, \"Shantilal\", \"Male\", 8000, \"Sales\"), \n",
    "    header(7, \"Vinod\",\"Male\", 7200, \"HR\"), \n",
    "    header(8, \"Vimla\", \"Female\", 6600, \"IT\"), \n",
    "    header(9, \"Jasmin\", \"Female\", 5400, \"Marketing\"), \n",
    "    header(10, \"Lovely\", \"Female\", 6300, \"Finance\"), \n",
    "    header(11, \"Mohan\", \"Male\", 5700, \"Sales\"), \n",
    "    header(12, \"Purvish\", \"Male\", 7000, \"HR\"), \n",
    "    header(13, \"Jinat\", \"Female\", 7100, \"IT\"), \n",
    "    header(14, \"Eva\", \"Female\", 6800,\"Marketing\"), \n",
    "    header(15, \"Jitendra\", \"Male\", 5000, \"Finance\"), \n",
    "    header(15, \"Rajkumar\", \"Male\", 4500, \"Finance\"), \n",
    "    header(15, \"Satish\", \"Male\", 4500, \"Finance\"), \n",
    "    header(15, \"Himmat\", \"Male\", 3500, \"Finance\")], 2).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----------+\n",
      "| ID|     Name|gender|Salary|Department|\n",
      "+---+---------+------+------+----------+\n",
      "|  1|     Deva|  Male|  5000|     Sales|\n",
      "|  2|    Jugnu|Female|  6000|        HR|\n",
      "|  3|   Kavita|Female|  7500|        IT|\n",
      "|  4|   Vikram|  Male|  6500| Marketing|\n",
      "|  5|  Shabana|Female|  5500|   Finance|\n",
      "|  6|Shantilal|  Male|  8000|     Sales|\n",
      "|  7|    Vinod|  Male|  7200|        HR|\n",
      "|  8|    Vimla|Female|  6600|        IT|\n",
      "|  9|   Jasmin|Female|  5400| Marketing|\n",
      "| 10|   Lovely|Female|  6300|   Finance|\n",
      "| 11|    Mohan|  Male|  5700|     Sales|\n",
      "| 12|  Purvish|  Male|  7000|        HR|\n",
      "| 13|    Jinat|Female|  7100|        IT|\n",
      "| 14|      Eva|Female|  6800| Marketing|\n",
      "| 15| Jitendra|  Male|  5000|   Finance|\n",
      "| 15| Rajkumar|  Male|  4500|   Finance|\n",
      "| 15|   Satish|  Male|  4500|   Finance|\n",
      "| 15|   Himmat|  Male|  3500|   Finance|\n",
      "+---+---------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the data in DataFrame \n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create an expression. These expressions are Column types. \n",
    "male_expr = expr(\"gender='Male'\") \n",
    "female_expr= expr(\"gender='Female'\") \n",
    "sal_expr= expr(\"Salary >=6600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----------+\n",
      "| ID|     Name|gender|Salary|Department|\n",
      "+---+---------+------+------+----------+\n",
      "|  1|     Deva|  Male|  5000|     Sales|\n",
      "|  4|   Vikram|  Male|  6500| Marketing|\n",
      "|  6|Shantilal|  Male|  8000|     Sales|\n",
      "|  7|    Vinod|  Male|  7200|        HR|\n",
      "| 11|    Mohan|  Male|  5700|     Sales|\n",
      "| 12|  Purvish|  Male|  7000|        HR|\n",
      "| 15| Jitendra|  Male|  5000|   Finance|\n",
      "| 15| Rajkumar|  Male|  4500|   Finance|\n",
      "| 15|   Satish|  Male|  4500|   Finance|\n",
      "| 15|   Himmat|  Male|  3500|   Finance|\n",
      "+---+---------+------+------+----------+\n",
      "\n",
      "+---+-------+------+------+----------+\n",
      "| ID|   Name|gender|Salary|Department|\n",
      "+---+-------+------+------+----------+\n",
      "|  2|  Jugnu|Female|  6000|        HR|\n",
      "|  3| Kavita|Female|  7500|        IT|\n",
      "|  5|Shabana|Female|  5500|   Finance|\n",
      "|  8|  Vimla|Female|  6600|        IT|\n",
      "|  9| Jasmin|Female|  5400| Marketing|\n",
      "| 10| Lovely|Female|  6300|   Finance|\n",
      "| 13|  Jinat|Female|  7100|        IT|\n",
      "| 14|    Eva|Female|  6800| Marketing|\n",
      "+---+-------+------+------+----------+\n",
      "\n",
      "+---+---------+------+------+----------+\n",
      "| ID|     Name|gender|Salary|Department|\n",
      "+---+---------+------+------+----------+\n",
      "|  3|   Kavita|Female|  7500|        IT|\n",
      "|  6|Shantilal|  Male|  8000|     Sales|\n",
      "|  7|    Vinod|  Male|  7200|        HR|\n",
      "|  8|    Vimla|Female|  6600|        IT|\n",
      "| 12|  Purvish|  Male|  7000|        HR|\n",
      "| 13|    Jinat|Female|  7100|        IT|\n",
      "| 14|      Eva|Female|  6800| Marketing|\n",
      "+---+---------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now apply these filters to the data \n",
    "employee_df.filter(male_expr).show() \n",
    "employee_df.filter(female_expr).show() \n",
    "employee_df.filter(sal_expr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      " |-- Array: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+---+------+------+--------------------+\n",
      "| ID|gender|Salary|               Array|\n",
      "+---+------+------+--------------------+\n",
      "|  3|Female|  7500|[Kavita, Female, IT]|\n",
      "|  6|  Male|  8000|[Shantilal, Male,...|\n",
      "|  7|  Male|  7200|   [Vinod, Male, HR]|\n",
      "|  8|Female|  6600| [Vimla, Female, IT]|\n",
      "| 12|  Male|  7000| [Purvish, Male, HR]|\n",
      "| 13|Female|  7100| [Jinat, Female, IT]|\n",
      "| 14|Female|  6800|[Eva, Female, Mar...|\n",
      "+---+------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now lets create array by combining multiple columns in DataFrame and drop the same column from output \n",
    "array_df = employee_df.filter(sal_expr)\\\n",
    ".withColumn(\"Array\" , array(\"Name\",\"gender\", \"Department\"))\\\n",
    ".drop(\"Name\",\"gende\", \"Department\")\n",
    "array_df.printSchema()\n",
    "array_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      " |-- Struct: struct (nullable = false)\n",
      " |    |-- Name: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- Department: string (nullable = true)\n",
      "\n",
      "+---+------+------+--------------------+\n",
      "| ID|gender|Salary|              Struct|\n",
      "+---+------+------+--------------------+\n",
      "|  3|Female|  7500|[Kavita, Female, IT]|\n",
      "|  6|  Male|  8000|[Shantilal, Male,...|\n",
      "|  7|  Male|  7200|   [Vinod, Male, HR]|\n",
      "|  8|Female|  6600| [Vimla, Female, IT]|\n",
      "| 12|  Male|  7000| [Purvish, Male, HR]|\n",
      "| 13|Female|  7100| [Jinat, Female, IT]|\n",
      "| 14|Female|  6800|[Eva, Female, Mar...|\n",
      "+---+------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now lets create array by combining multiple columns in DataFrame and drop the same column from output  \n",
    "struct_df = employee_df.filter(sal_expr)\\\n",
    ".withColumn(\"Struct\", struct(\"Name\",\"gender\", \"Department\"))\\\n",
    ".drop(\"Name\",\"gende\", \"Department\")\n",
    "\n",
    "struct_df.printSchema()\n",
    "\n",
    "struct_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+\n",
      "| ID|     Name|               Array|\n",
      "+---+---------+--------------------+\n",
      "|  3|   Kavita|[Kavita, Female, IT]|\n",
      "|  6|Shantilal|[Shantilal, Male,...|\n",
      "|  7|    Vinod|   [Vinod, Male, HR]|\n",
      "|  8|    Vimla| [Vimla, Female, IT]|\n",
      "| 12|  Purvish| [Purvish, Male, HR]|\n",
      "| 13|    Jinat| [Jinat, Female, IT]|\n",
      "| 14|      Eva|[Eva, Female, Mar...|\n",
      "+---+---------+--------------------+\n",
      "\n",
      "+---+---------+--------------------+\n",
      "| ID|     Name|              Struct|\n",
      "+---+---------+--------------------+\n",
      "|  3|   Kavita|[Kavita, Female, IT]|\n",
      "|  6|Shantilal|[Shantilal, Male,...|\n",
      "|  7|    Vinod|   [Vinod, Male, HR]|\n",
      "|  8|    Vimla| [Vimla, Female, IT]|\n",
      "| 12|  Purvish| [Purvish, Male, HR]|\n",
      "| 13|    Jinat| [Jinat, Female, IT]|\n",
      "| 14|      Eva|[Eva, Female, Mar...|\n",
      "+---+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Even both support mixed datatypes as well \n",
    "employee_df.filter(sal_expr)\\\n",
    ".withColumn(\"Array\" , array(\"Name\",\"gender\", \"Department\"))\\\n",
    ".drop(\"gender\", \"Department\", \"Salary\").show() \n",
    "\n",
    "employee_df.filter(sal_expr)\\\n",
    ".withColumn(\"Struct\", struct(\"Name\",\"gender\", \"Department\"))\\\n",
    ".drop(\"gender\", \"Department\", \"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monotonically_increasing_id() \n",
    "#Lets create data with 4 partitions \n",
    "employee_df_2 = spark.sparkContext.parallelize([\n",
    "    header(1, \"Deva\", \"Male\", 5000, \"Sales\"), \n",
    "    header(2, \"Jugnu\", \"Female\", 6000, \"HR\"), \n",
    "    header(3, \"Kavita\", \"Female\", 7500, \"IT\"), \n",
    "    header(4, \"Vikram\", \"Male\", 6500, \"Marketing\"),\n",
    "    header(5, \"Shabana\", \"Female\", 5500, \"Finance\"), \n",
    "    header(6, \"Shantilal\", \"Male\", 8000, \"Sales\"), \n",
    "    header(7, \"Vinod\", \"Male\", 7200, \"HR\"), \n",
    "    header(8, \"Vimla\", \"Female\", 6600, \"IT\"),\n",
    "    header(9, \"Jasmin\", \"Female\", 5400, \"Marketing\"),\n",
    "    header(10, \"Lovely\", \"Female\", 6300, \"Finance\"), \n",
    "    header(11, \"Mohan\", \"Male\", 5700, \"Sales\"), \n",
    "    header(12, \"Purvish\", \"Male\", 7000, \"HR\"), \n",
    "    header(13, \"Jinat\", \"Female\", 7100, \"IT\"), \n",
    "    header(14, \"Eva\", \"Female\", 6800,\"Marketing\"), \n",
    "    header(15, \"Jitendra\", \"Male\", 5000, \"Finance\") , \n",
    "    header(15, \"Rajkumar\", \"Male\", 4500, \"Finance\") , \n",
    "    header(15, \"Satish\", \"Male\", 4500, \"Finance\") , \n",
    "    header(15, \"Himmat\", \"Male\", 3500, \"Finance\")], 4).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate monotonically_increasing_id() for each row. \n",
    "#It is a 64 bit integers \n",
    "#Generated ID must be unique and increasing only. \n",
    "#It can not be consecutive \n",
    "#The current implementation puts the partition ID in the upper 31 bits, \n",
    "# and the record number within each partition in the lower 33 bits.  \n",
    "#The assumption is that the data frame has less than 1 billion partitions,\n",
    "#and each partition has less than 8 billion records. \n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+----------+-----------+\n",
      "| ID|     Name|gender|Salary|Department|  unique_id|\n",
      "+---+---------+------+------+----------+-----------+\n",
      "|  1|     Deva|  Male|  5000|     Sales|          0|\n",
      "|  2|    Jugnu|Female|  6000|        HR|          1|\n",
      "|  3|   Kavita|Female|  7500|        IT|          2|\n",
      "|  4|   Vikram|  Male|  6500| Marketing|          3|\n",
      "|  5|  Shabana|Female|  5500|   Finance| 8589934592|\n",
      "|  6|Shantilal|  Male|  8000|     Sales| 8589934593|\n",
      "|  7|    Vinod|  Male|  7200|        HR| 8589934594|\n",
      "|  8|    Vimla|Female|  6600|        IT| 8589934595|\n",
      "|  9|   Jasmin|Female|  5400| Marketing|17179869184|\n",
      "| 10|   Lovely|Female|  6300|   Finance|17179869185|\n",
      "| 11|    Mohan|  Male|  5700|     Sales|17179869186|\n",
      "| 12|  Purvish|  Male|  7000|        HR|17179869187|\n",
      "| 13|    Jinat|Female|  7100|        IT|25769803776|\n",
      "| 14|      Eva|Female|  6800| Marketing|25769803777|\n",
      "| 15| Jitendra|  Male|  5000|   Finance|25769803778|\n",
      "| 15| Rajkumar|  Male|  4500|   Finance|25769803779|\n",
      "| 15|   Satish|  Male|  4500|   Finance|25769803780|\n",
      "| 15|   Himmat|  Male|  3500|   Finance|25769803781|\n",
      "+---+---------+------+------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df_2.withColumn(\"unique_id\", monotonically_increasing_id()).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
