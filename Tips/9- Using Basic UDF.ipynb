{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"test\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_salary(s): return s + s*20/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.createDataFrame([\n",
    "Row(1, \"Deva\", \"Male\", 5000, \"Sales\"), \n",
    "Row(2, \"Jugnu\", \"Female\", 6000, \"HR\"), \n",
    "Row(3, \"Kavita\", \"Female\", 7500, \"IT\"), \n",
    "Row(4, \"Vikram\", \"Male\", 6500, \"Marketing\"), \n",
    "Row(5, \"Shabana\", \"Female\", 5500, \"Finance\"), \n",
    "Row(6, \"Shantilal\", \"Male\", 8000, \"Sales\"), \n",
    "Row(7, \"Vinod\", \"Male\", 7200, \"HR\"), \n",
    "Row(8, \"Vimla\", \"Female\", 6600, \"IT\"), \n",
    "Row(9, \"Jasmin\", \"Female\", 5400, \"Marketing\"), \n",
    "Row(10, \"Lovely\", \"Female\", 6300, \"Finance\"), \n",
    "Row(11, \"Mohan\", \"Male\", 5700, \"Sales\"), \n",
    "Row(12, \"Purvish\", \"Male\", 7000, \"HR\"), \n",
    "Row(13, \"Jinat\", \"Female\", 7100, \"IT\"), \n",
    "Row(14, \"Eva\", \"Female\", 6800,\"Marketing\"), \n",
    "Row(15, \"Jitendra\", \"Male\", 5000, \"Finance\"), \n",
    "Row(16, \"Rajkumar\", \"Male\", 4500, \"Finance\"), \n",
    "Row(17, \"Satish\", \"Male\", 4500, \"Finance\"), \n",
    "Row(18, \"Himmat\", \"Male\", 3500, \"Finance\")]).toDF(\"id\" , \"name\" , \"Gender\" , \"Salary\" , \"dept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------+---------+\n",
      "| id|     name|Gender|Salary|     dept|\n",
      "+---+---------+------+------+---------+\n",
      "|  1|     Deva|  Male|  5000|    Sales|\n",
      "|  2|    Jugnu|Female|  6000|       HR|\n",
      "|  3|   Kavita|Female|  7500|       IT|\n",
      "|  4|   Vikram|  Male|  6500|Marketing|\n",
      "|  5|  Shabana|Female|  5500|  Finance|\n",
      "|  6|Shantilal|  Male|  8000|    Sales|\n",
      "|  7|    Vinod|  Male|  7200|       HR|\n",
      "|  8|    Vimla|Female|  6600|       IT|\n",
      "|  9|   Jasmin|Female|  5400|Marketing|\n",
      "| 10|   Lovely|Female|  6300|  Finance|\n",
      "| 11|    Mohan|  Male|  5700|    Sales|\n",
      "| 12|  Purvish|  Male|  7000|       HR|\n",
      "| 13|    Jinat|Female|  7100|       IT|\n",
      "| 14|      Eva|Female|  6800|Marketing|\n",
      "| 15| Jitendra|  Male|  5000|  Finance|\n",
      "| 16| Rajkumar|  Male|  4500|  Finance|\n",
      "| 17|   Satish|  Male|  4500|  Finance|\n",
      "| 18|   Himmat|  Male|  3500|  Finance|\n",
      "+---+---------+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define UDF function, which add 20% bonus to salary\n",
    "#However, remember for SparkSQL, it is difficult to optimize #UDF functions.\n",
    "#Hence, you should use as less as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.calculate_total_salary(s)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#register UDF\n",
    "spark.udf.register(\"calculate_total_salary\", calculate_total_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Salary| Total|\n",
      "+------+------+\n",
      "|  5000|6000.0|\n",
      "|  6000|7200.0|\n",
      "|  7500|9000.0|\n",
      "|  6500|7800.0|\n",
      "|  5500|6600.0|\n",
      "|  8000|9600.0|\n",
      "|  7200|8640.0|\n",
      "|  6600|7920.0|\n",
      "|  5400|6480.0|\n",
      "|  6300|7560.0|\n",
      "|  5700|6840.0|\n",
      "|  7000|8400.0|\n",
      "|  7100|8520.0|\n",
      "|  6800|8160.0|\n",
      "|  5000|6000.0|\n",
      "|  4500|5400.0|\n",
      "|  4500|5400.0|\n",
      "|  3500|4200.0|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Salary, calculate_total_salary(df.Salary).alias(\"Total\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function(name='!', description=None, className='org.apache.spark.sql.catalyst.expressions.Not', isTemporary=True),\n",
       " Function(name='%', description=None, className='org.apache.spark.sql.catalyst.expressions.Remainder', isTemporary=True),\n",
       " Function(name='&', description=None, className='org.apache.spark.sql.catalyst.expressions.BitwiseAnd', isTemporary=True),\n",
       " Function(name='*', description=None, className='org.apache.spark.sql.catalyst.expressions.Multiply', isTemporary=True),\n",
       " Function(name='+', description=None, className='org.apache.spark.sql.catalyst.expressions.Add', isTemporary=True),\n",
       " Function(name='-', description=None, className='org.apache.spark.sql.catalyst.expressions.Subtract', isTemporary=True),\n",
       " Function(name='/', description=None, className='org.apache.spark.sql.catalyst.expressions.Divide', isTemporary=True),\n",
       " Function(name='<', description=None, className='org.apache.spark.sql.catalyst.expressions.LessThan', isTemporary=True),\n",
       " Function(name='<=', description=None, className='org.apache.spark.sql.catalyst.expressions.LessThanOrEqual', isTemporary=True),\n",
       " Function(name='<=>', description=None, className='org.apache.spark.sql.catalyst.expressions.EqualNullSafe', isTemporary=True),\n",
       " Function(name='=', description=None, className='org.apache.spark.sql.catalyst.expressions.EqualTo', isTemporary=True),\n",
       " Function(name='==', description=None, className='org.apache.spark.sql.catalyst.expressions.EqualTo', isTemporary=True),\n",
       " Function(name='>', description=None, className='org.apache.spark.sql.catalyst.expressions.GreaterThan', isTemporary=True),\n",
       " Function(name='>=', description=None, className='org.apache.spark.sql.catalyst.expressions.GreaterThanOrEqual', isTemporary=True),\n",
       " Function(name='^', description=None, className='org.apache.spark.sql.catalyst.expressions.BitwiseXor', isTemporary=True),\n",
       " Function(name='abs', description=None, className='org.apache.spark.sql.catalyst.expressions.Abs', isTemporary=True),\n",
       " Function(name='acos', description=None, className='org.apache.spark.sql.catalyst.expressions.Acos', isTemporary=True),\n",
       " Function(name='add_months', description=None, className='org.apache.spark.sql.catalyst.expressions.AddMonths', isTemporary=True),\n",
       " Function(name='aggregate', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayAggregate', isTemporary=True),\n",
       " Function(name='and', description=None, className='org.apache.spark.sql.catalyst.expressions.And', isTemporary=True),\n",
       " Function(name='approx_count_distinct', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.HyperLogLogPlusPlus', isTemporary=True),\n",
       " Function(name='approx_percentile', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile', isTemporary=True),\n",
       " Function(name='array', description=None, className='org.apache.spark.sql.catalyst.expressions.CreateArray', isTemporary=True),\n",
       " Function(name='array_contains', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayContains', isTemporary=True),\n",
       " Function(name='array_distinct', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayDistinct', isTemporary=True),\n",
       " Function(name='array_except', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayExcept', isTemporary=True),\n",
       " Function(name='array_intersect', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayIntersect', isTemporary=True),\n",
       " Function(name='array_join', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayJoin', isTemporary=True),\n",
       " Function(name='array_max', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayMax', isTemporary=True),\n",
       " Function(name='array_min', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayMin', isTemporary=True),\n",
       " Function(name='array_position', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayPosition', isTemporary=True),\n",
       " Function(name='array_remove', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayRemove', isTemporary=True),\n",
       " Function(name='array_repeat', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayRepeat', isTemporary=True),\n",
       " Function(name='array_sort', description=None, className='org.apache.spark.sql.catalyst.expressions.ArraySort', isTemporary=True),\n",
       " Function(name='array_union', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayUnion', isTemporary=True),\n",
       " Function(name='arrays_overlap', description=None, className='org.apache.spark.sql.catalyst.expressions.ArraysOverlap', isTemporary=True),\n",
       " Function(name='arrays_zip', description=None, className='org.apache.spark.sql.catalyst.expressions.ArraysZip', isTemporary=True),\n",
       " Function(name='ascii', description=None, className='org.apache.spark.sql.catalyst.expressions.Ascii', isTemporary=True),\n",
       " Function(name='asin', description=None, className='org.apache.spark.sql.catalyst.expressions.Asin', isTemporary=True),\n",
       " Function(name='assert_true', description=None, className='org.apache.spark.sql.catalyst.expressions.AssertTrue', isTemporary=True),\n",
       " Function(name='atan', description=None, className='org.apache.spark.sql.catalyst.expressions.Atan', isTemporary=True),\n",
       " Function(name='atan2', description=None, className='org.apache.spark.sql.catalyst.expressions.Atan2', isTemporary=True),\n",
       " Function(name='avg', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Average', isTemporary=True),\n",
       " Function(name='base64', description=None, className='org.apache.spark.sql.catalyst.expressions.Base64', isTemporary=True),\n",
       " Function(name='bigint', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='bin', description=None, className='org.apache.spark.sql.catalyst.expressions.Bin', isTemporary=True),\n",
       " Function(name='binary', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='bit_length', description=None, className='org.apache.spark.sql.catalyst.expressions.BitLength', isTemporary=True),\n",
       " Function(name='boolean', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='bround', description=None, className='org.apache.spark.sql.catalyst.expressions.BRound', isTemporary=True),\n",
       " Function(name='calculate_total_salary', description=None, className=None, isTemporary=True),\n",
       " Function(name='cardinality', description=None, className='org.apache.spark.sql.catalyst.expressions.Size', isTemporary=True),\n",
       " Function(name='cast', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='cbrt', description=None, className='org.apache.spark.sql.catalyst.expressions.Cbrt', isTemporary=True),\n",
       " Function(name='ceil', description=None, className='org.apache.spark.sql.catalyst.expressions.Ceil', isTemporary=True),\n",
       " Function(name='ceiling', description=None, className='org.apache.spark.sql.catalyst.expressions.Ceil', isTemporary=True),\n",
       " Function(name='char', description=None, className='org.apache.spark.sql.catalyst.expressions.Chr', isTemporary=True),\n",
       " Function(name='char_length', description=None, className='org.apache.spark.sql.catalyst.expressions.Length', isTemporary=True),\n",
       " Function(name='character_length', description=None, className='org.apache.spark.sql.catalyst.expressions.Length', isTemporary=True),\n",
       " Function(name='chr', description=None, className='org.apache.spark.sql.catalyst.expressions.Chr', isTemporary=True),\n",
       " Function(name='coalesce', description=None, className='org.apache.spark.sql.catalyst.expressions.Coalesce', isTemporary=True),\n",
       " Function(name='collect_list', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.CollectList', isTemporary=True),\n",
       " Function(name='collect_set', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.CollectSet', isTemporary=True),\n",
       " Function(name='concat', description=None, className='org.apache.spark.sql.catalyst.expressions.Concat', isTemporary=True),\n",
       " Function(name='concat_ws', description=None, className='org.apache.spark.sql.catalyst.expressions.ConcatWs', isTemporary=True),\n",
       " Function(name='conv', description=None, className='org.apache.spark.sql.catalyst.expressions.Conv', isTemporary=True),\n",
       " Function(name='corr', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Corr', isTemporary=True),\n",
       " Function(name='cos', description=None, className='org.apache.spark.sql.catalyst.expressions.Cos', isTemporary=True),\n",
       " Function(name='cosh', description=None, className='org.apache.spark.sql.catalyst.expressions.Cosh', isTemporary=True),\n",
       " Function(name='cot', description=None, className='org.apache.spark.sql.catalyst.expressions.Cot', isTemporary=True),\n",
       " Function(name='count', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Count', isTemporary=True),\n",
       " Function(name='count_min_sketch', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.CountMinSketchAgg', isTemporary=True),\n",
       " Function(name='covar_pop', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.CovPopulation', isTemporary=True),\n",
       " Function(name='covar_samp', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.CovSample', isTemporary=True),\n",
       " Function(name='crc32', description=None, className='org.apache.spark.sql.catalyst.expressions.Crc32', isTemporary=True),\n",
       " Function(name='cube', description=None, className='org.apache.spark.sql.catalyst.expressions.Cube', isTemporary=True),\n",
       " Function(name='cume_dist', description=None, className='org.apache.spark.sql.catalyst.expressions.CumeDist', isTemporary=True),\n",
       " Function(name='current_database', description=None, className='org.apache.spark.sql.catalyst.expressions.CurrentDatabase', isTemporary=True),\n",
       " Function(name='current_date', description=None, className='org.apache.spark.sql.catalyst.expressions.CurrentDate', isTemporary=True),\n",
       " Function(name='current_timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.CurrentTimestamp', isTemporary=True),\n",
       " Function(name='date', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='date_add', description=None, className='org.apache.spark.sql.catalyst.expressions.DateAdd', isTemporary=True),\n",
       " Function(name='date_format', description=None, className='org.apache.spark.sql.catalyst.expressions.DateFormatClass', isTemporary=True),\n",
       " Function(name='date_sub', description=None, className='org.apache.spark.sql.catalyst.expressions.DateSub', isTemporary=True),\n",
       " Function(name='date_trunc', description=None, className='org.apache.spark.sql.catalyst.expressions.TruncTimestamp', isTemporary=True),\n",
       " Function(name='datediff', description=None, className='org.apache.spark.sql.catalyst.expressions.DateDiff', isTemporary=True),\n",
       " Function(name='day', description=None, className='org.apache.spark.sql.catalyst.expressions.DayOfMonth', isTemporary=True),\n",
       " Function(name='dayofmonth', description=None, className='org.apache.spark.sql.catalyst.expressions.DayOfMonth', isTemporary=True),\n",
       " Function(name='dayofweek', description=None, className='org.apache.spark.sql.catalyst.expressions.DayOfWeek', isTemporary=True),\n",
       " Function(name='dayofyear', description=None, className='org.apache.spark.sql.catalyst.expressions.DayOfYear', isTemporary=True),\n",
       " Function(name='decimal', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='decode', description=None, className='org.apache.spark.sql.catalyst.expressions.Decode', isTemporary=True),\n",
       " Function(name='degrees', description=None, className='org.apache.spark.sql.catalyst.expressions.ToDegrees', isTemporary=True),\n",
       " Function(name='dense_rank', description=None, className='org.apache.spark.sql.catalyst.expressions.DenseRank', isTemporary=True),\n",
       " Function(name='double', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='e', description=None, className='org.apache.spark.sql.catalyst.expressions.EulerNumber', isTemporary=True),\n",
       " Function(name='element_at', description=None, className='org.apache.spark.sql.catalyst.expressions.ElementAt', isTemporary=True),\n",
       " Function(name='elt', description=None, className='org.apache.spark.sql.catalyst.expressions.Elt', isTemporary=True),\n",
       " Function(name='encode', description=None, className='org.apache.spark.sql.catalyst.expressions.Encode', isTemporary=True),\n",
       " Function(name='exists', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayExists', isTemporary=True),\n",
       " Function(name='exp', description=None, className='org.apache.spark.sql.catalyst.expressions.Exp', isTemporary=True),\n",
       " Function(name='explode', description=None, className='org.apache.spark.sql.catalyst.expressions.Explode', isTemporary=True),\n",
       " Function(name='explode_outer', description=None, className='org.apache.spark.sql.catalyst.expressions.Explode', isTemporary=True),\n",
       " Function(name='expm1', description=None, className='org.apache.spark.sql.catalyst.expressions.Expm1', isTemporary=True),\n",
       " Function(name='factorial', description=None, className='org.apache.spark.sql.catalyst.expressions.Factorial', isTemporary=True),\n",
       " Function(name='filter', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayFilter', isTemporary=True),\n",
       " Function(name='find_in_set', description=None, className='org.apache.spark.sql.catalyst.expressions.FindInSet', isTemporary=True),\n",
       " Function(name='first', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.First', isTemporary=True),\n",
       " Function(name='first_value', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.First', isTemporary=True),\n",
       " Function(name='flatten', description=None, className='org.apache.spark.sql.catalyst.expressions.Flatten', isTemporary=True),\n",
       " Function(name='float', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='floor', description=None, className='org.apache.spark.sql.catalyst.expressions.Floor', isTemporary=True),\n",
       " Function(name='format_number', description=None, className='org.apache.spark.sql.catalyst.expressions.FormatNumber', isTemporary=True),\n",
       " Function(name='format_string', description=None, className='org.apache.spark.sql.catalyst.expressions.FormatString', isTemporary=True),\n",
       " Function(name='from_json', description=None, className='org.apache.spark.sql.catalyst.expressions.JsonToStructs', isTemporary=True),\n",
       " Function(name='from_unixtime', description=None, className='org.apache.spark.sql.catalyst.expressions.FromUnixTime', isTemporary=True),\n",
       " Function(name='from_utc_timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.FromUTCTimestamp', isTemporary=True),\n",
       " Function(name='get_json_object', description=None, className='org.apache.spark.sql.catalyst.expressions.GetJsonObject', isTemporary=True),\n",
       " Function(name='greatest', description=None, className='org.apache.spark.sql.catalyst.expressions.Greatest', isTemporary=True),\n",
       " Function(name='grouping', description=None, className='org.apache.spark.sql.catalyst.expressions.Grouping', isTemporary=True),\n",
       " Function(name='grouping_id', description=None, className='org.apache.spark.sql.catalyst.expressions.GroupingID', isTemporary=True),\n",
       " Function(name='hash', description=None, className='org.apache.spark.sql.catalyst.expressions.Murmur3Hash', isTemporary=True),\n",
       " Function(name='hex', description=None, className='org.apache.spark.sql.catalyst.expressions.Hex', isTemporary=True),\n",
       " Function(name='hour', description=None, className='org.apache.spark.sql.catalyst.expressions.Hour', isTemporary=True),\n",
       " Function(name='hypot', description=None, className='org.apache.spark.sql.catalyst.expressions.Hypot', isTemporary=True),\n",
       " Function(name='if', description=None, className='org.apache.spark.sql.catalyst.expressions.If', isTemporary=True),\n",
       " Function(name='ifnull', description=None, className='org.apache.spark.sql.catalyst.expressions.IfNull', isTemporary=True),\n",
       " Function(name='in', description=None, className='org.apache.spark.sql.catalyst.expressions.In', isTemporary=True),\n",
       " Function(name='initcap', description=None, className='org.apache.spark.sql.catalyst.expressions.InitCap', isTemporary=True),\n",
       " Function(name='inline', description=None, className='org.apache.spark.sql.catalyst.expressions.Inline', isTemporary=True),\n",
       " Function(name='inline_outer', description=None, className='org.apache.spark.sql.catalyst.expressions.Inline', isTemporary=True),\n",
       " Function(name='input_file_block_length', description=None, className='org.apache.spark.sql.catalyst.expressions.InputFileBlockLength', isTemporary=True),\n",
       " Function(name='input_file_block_start', description=None, className='org.apache.spark.sql.catalyst.expressions.InputFileBlockStart', isTemporary=True),\n",
       " Function(name='input_file_name', description=None, className='org.apache.spark.sql.catalyst.expressions.InputFileName', isTemporary=True),\n",
       " Function(name='instr', description=None, className='org.apache.spark.sql.catalyst.expressions.StringInstr', isTemporary=True),\n",
       " Function(name='int', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='isnan', description=None, className='org.apache.spark.sql.catalyst.expressions.IsNaN', isTemporary=True),\n",
       " Function(name='isnotnull', description=None, className='org.apache.spark.sql.catalyst.expressions.IsNotNull', isTemporary=True),\n",
       " Function(name='isnull', description=None, className='org.apache.spark.sql.catalyst.expressions.IsNull', isTemporary=True),\n",
       " Function(name='java_method', description=None, className='org.apache.spark.sql.catalyst.expressions.CallMethodViaReflection', isTemporary=True),\n",
       " Function(name='json_tuple', description=None, className='org.apache.spark.sql.catalyst.expressions.JsonTuple', isTemporary=True),\n",
       " Function(name='kurtosis', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Kurtosis', isTemporary=True),\n",
       " Function(name='lag', description=None, className='org.apache.spark.sql.catalyst.expressions.Lag', isTemporary=True),\n",
       " Function(name='last', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Last', isTemporary=True),\n",
       " Function(name='last_day', description=None, className='org.apache.spark.sql.catalyst.expressions.LastDay', isTemporary=True),\n",
       " Function(name='last_value', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Last', isTemporary=True),\n",
       " Function(name='lcase', description=None, className='org.apache.spark.sql.catalyst.expressions.Lower', isTemporary=True),\n",
       " Function(name='lead', description=None, className='org.apache.spark.sql.catalyst.expressions.Lead', isTemporary=True),\n",
       " Function(name='least', description=None, className='org.apache.spark.sql.catalyst.expressions.Least', isTemporary=True),\n",
       " Function(name='left', description=None, className='org.apache.spark.sql.catalyst.expressions.Left', isTemporary=True),\n",
       " Function(name='length', description=None, className='org.apache.spark.sql.catalyst.expressions.Length', isTemporary=True),\n",
       " Function(name='levenshtein', description=None, className='org.apache.spark.sql.catalyst.expressions.Levenshtein', isTemporary=True),\n",
       " Function(name='like', description=None, className='org.apache.spark.sql.catalyst.expressions.Like', isTemporary=True),\n",
       " Function(name='ln', description=None, className='org.apache.spark.sql.catalyst.expressions.Log', isTemporary=True),\n",
       " Function(name='locate', description=None, className='org.apache.spark.sql.catalyst.expressions.StringLocate', isTemporary=True),\n",
       " Function(name='log', description=None, className='org.apache.spark.sql.catalyst.expressions.Logarithm', isTemporary=True),\n",
       " Function(name='log10', description=None, className='org.apache.spark.sql.catalyst.expressions.Log10', isTemporary=True),\n",
       " Function(name='log1p', description=None, className='org.apache.spark.sql.catalyst.expressions.Log1p', isTemporary=True),\n",
       " Function(name='log2', description=None, className='org.apache.spark.sql.catalyst.expressions.Log2', isTemporary=True),\n",
       " Function(name='lower', description=None, className='org.apache.spark.sql.catalyst.expressions.Lower', isTemporary=True),\n",
       " Function(name='lpad', description=None, className='org.apache.spark.sql.catalyst.expressions.StringLPad', isTemporary=True),\n",
       " Function(name='ltrim', description=None, className='org.apache.spark.sql.catalyst.expressions.StringTrimLeft', isTemporary=True),\n",
       " Function(name='map', description=None, className='org.apache.spark.sql.catalyst.expressions.CreateMap', isTemporary=True),\n",
       " Function(name='map_concat', description=None, className='org.apache.spark.sql.catalyst.expressions.MapConcat', isTemporary=True),\n",
       " Function(name='map_from_arrays', description=None, className='org.apache.spark.sql.catalyst.expressions.MapFromArrays', isTemporary=True),\n",
       " Function(name='map_from_entries', description=None, className='org.apache.spark.sql.catalyst.expressions.MapFromEntries', isTemporary=True),\n",
       " Function(name='map_keys', description=None, className='org.apache.spark.sql.catalyst.expressions.MapKeys', isTemporary=True),\n",
       " Function(name='map_values', description=None, className='org.apache.spark.sql.catalyst.expressions.MapValues', isTemporary=True),\n",
       " Function(name='max', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Max', isTemporary=True),\n",
       " Function(name='md5', description=None, className='org.apache.spark.sql.catalyst.expressions.Md5', isTemporary=True),\n",
       " Function(name='mean', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Average', isTemporary=True),\n",
       " Function(name='min', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Min', isTemporary=True),\n",
       " Function(name='minute', description=None, className='org.apache.spark.sql.catalyst.expressions.Minute', isTemporary=True),\n",
       " Function(name='mod', description=None, className='org.apache.spark.sql.catalyst.expressions.Remainder', isTemporary=True),\n",
       " Function(name='monotonically_increasing_id', description=None, className='org.apache.spark.sql.catalyst.expressions.MonotonicallyIncreasingID', isTemporary=True),\n",
       " Function(name='month', description=None, className='org.apache.spark.sql.catalyst.expressions.Month', isTemporary=True),\n",
       " Function(name='months_between', description=None, className='org.apache.spark.sql.catalyst.expressions.MonthsBetween', isTemporary=True),\n",
       " Function(name='named_struct', description=None, className='org.apache.spark.sql.catalyst.expressions.CreateNamedStruct', isTemporary=True),\n",
       " Function(name='nanvl', description=None, className='org.apache.spark.sql.catalyst.expressions.NaNvl', isTemporary=True),\n",
       " Function(name='negative', description=None, className='org.apache.spark.sql.catalyst.expressions.UnaryMinus', isTemporary=True),\n",
       " Function(name='next_day', description=None, className='org.apache.spark.sql.catalyst.expressions.NextDay', isTemporary=True),\n",
       " Function(name='not', description=None, className='org.apache.spark.sql.catalyst.expressions.Not', isTemporary=True),\n",
       " Function(name='now', description=None, className='org.apache.spark.sql.catalyst.expressions.CurrentTimestamp', isTemporary=True),\n",
       " Function(name='ntile', description=None, className='org.apache.spark.sql.catalyst.expressions.NTile', isTemporary=True),\n",
       " Function(name='nullif', description=None, className='org.apache.spark.sql.catalyst.expressions.NullIf', isTemporary=True),\n",
       " Function(name='nvl', description=None, className='org.apache.spark.sql.catalyst.expressions.Nvl', isTemporary=True),\n",
       " Function(name='nvl2', description=None, className='org.apache.spark.sql.catalyst.expressions.Nvl2', isTemporary=True),\n",
       " Function(name='octet_length', description=None, className='org.apache.spark.sql.catalyst.expressions.OctetLength', isTemporary=True),\n",
       " Function(name='or', description=None, className='org.apache.spark.sql.catalyst.expressions.Or', isTemporary=True),\n",
       " Function(name='parse_url', description=None, className='org.apache.spark.sql.catalyst.expressions.ParseUrl', isTemporary=True),\n",
       " Function(name='percent_rank', description=None, className='org.apache.spark.sql.catalyst.expressions.PercentRank', isTemporary=True),\n",
       " Function(name='percentile', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Percentile', isTemporary=True),\n",
       " Function(name='percentile_approx', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.ApproximatePercentile', isTemporary=True),\n",
       " Function(name='pi', description=None, className='org.apache.spark.sql.catalyst.expressions.Pi', isTemporary=True),\n",
       " Function(name='pmod', description=None, className='org.apache.spark.sql.catalyst.expressions.Pmod', isTemporary=True),\n",
       " Function(name='posexplode', description=None, className='org.apache.spark.sql.catalyst.expressions.PosExplode', isTemporary=True),\n",
       " Function(name='posexplode_outer', description=None, className='org.apache.spark.sql.catalyst.expressions.PosExplode', isTemporary=True),\n",
       " Function(name='position', description=None, className='org.apache.spark.sql.catalyst.expressions.StringLocate', isTemporary=True),\n",
       " Function(name='positive', description=None, className='org.apache.spark.sql.catalyst.expressions.UnaryPositive', isTemporary=True),\n",
       " Function(name='pow', description=None, className='org.apache.spark.sql.catalyst.expressions.Pow', isTemporary=True),\n",
       " Function(name='power', description=None, className='org.apache.spark.sql.catalyst.expressions.Pow', isTemporary=True),\n",
       " Function(name='printf', description=None, className='org.apache.spark.sql.catalyst.expressions.FormatString', isTemporary=True),\n",
       " Function(name='quarter', description=None, className='org.apache.spark.sql.catalyst.expressions.Quarter', isTemporary=True),\n",
       " Function(name='radians', description=None, className='org.apache.spark.sql.catalyst.expressions.ToRadians', isTemporary=True),\n",
       " Function(name='rand', description=None, className='org.apache.spark.sql.catalyst.expressions.Rand', isTemporary=True),\n",
       " Function(name='randn', description=None, className='org.apache.spark.sql.catalyst.expressions.Randn', isTemporary=True),\n",
       " Function(name='rank', description=None, className='org.apache.spark.sql.catalyst.expressions.Rank', isTemporary=True),\n",
       " Function(name='reflect', description=None, className='org.apache.spark.sql.catalyst.expressions.CallMethodViaReflection', isTemporary=True),\n",
       " Function(name='regexp_extract', description=None, className='org.apache.spark.sql.catalyst.expressions.RegExpExtract', isTemporary=True),\n",
       " Function(name='regexp_replace', description=None, className='org.apache.spark.sql.catalyst.expressions.RegExpReplace', isTemporary=True),\n",
       " Function(name='repeat', description=None, className='org.apache.spark.sql.catalyst.expressions.StringRepeat', isTemporary=True),\n",
       " Function(name='replace', description=None, className='org.apache.spark.sql.catalyst.expressions.StringReplace', isTemporary=True),\n",
       " Function(name='reverse', description=None, className='org.apache.spark.sql.catalyst.expressions.Reverse', isTemporary=True),\n",
       " Function(name='right', description=None, className='org.apache.spark.sql.catalyst.expressions.Right', isTemporary=True),\n",
       " Function(name='rint', description=None, className='org.apache.spark.sql.catalyst.expressions.Rint', isTemporary=True),\n",
       " Function(name='rlike', description=None, className='org.apache.spark.sql.catalyst.expressions.RLike', isTemporary=True),\n",
       " Function(name='rollup', description=None, className='org.apache.spark.sql.catalyst.expressions.Rollup', isTemporary=True),\n",
       " Function(name='round', description=None, className='org.apache.spark.sql.catalyst.expressions.Round', isTemporary=True),\n",
       " Function(name='row_number', description=None, className='org.apache.spark.sql.catalyst.expressions.RowNumber', isTemporary=True),\n",
       " Function(name='rpad', description=None, className='org.apache.spark.sql.catalyst.expressions.StringRPad', isTemporary=True),\n",
       " Function(name='rtrim', description=None, className='org.apache.spark.sql.catalyst.expressions.StringTrimRight', isTemporary=True),\n",
       " Function(name='schema_of_json', description=None, className='org.apache.spark.sql.catalyst.expressions.SchemaOfJson', isTemporary=True),\n",
       " Function(name='second', description=None, className='org.apache.spark.sql.catalyst.expressions.Second', isTemporary=True),\n",
       " Function(name='sentences', description=None, className='org.apache.spark.sql.catalyst.expressions.Sentences', isTemporary=True),\n",
       " Function(name='sequence', description=None, className='org.apache.spark.sql.catalyst.expressions.Sequence', isTemporary=True),\n",
       " Function(name='sha', description=None, className='org.apache.spark.sql.catalyst.expressions.Sha1', isTemporary=True),\n",
       " Function(name='sha1', description=None, className='org.apache.spark.sql.catalyst.expressions.Sha1', isTemporary=True),\n",
       " Function(name='sha2', description=None, className='org.apache.spark.sql.catalyst.expressions.Sha2', isTemporary=True),\n",
       " Function(name='shiftleft', description=None, className='org.apache.spark.sql.catalyst.expressions.ShiftLeft', isTemporary=True),\n",
       " Function(name='shiftright', description=None, className='org.apache.spark.sql.catalyst.expressions.ShiftRight', isTemporary=True),\n",
       " Function(name='shiftrightunsigned', description=None, className='org.apache.spark.sql.catalyst.expressions.ShiftRightUnsigned', isTemporary=True),\n",
       " Function(name='shuffle', description=None, className='org.apache.spark.sql.catalyst.expressions.Shuffle', isTemporary=True),\n",
       " Function(name='sign', description=None, className='org.apache.spark.sql.catalyst.expressions.Signum', isTemporary=True),\n",
       " Function(name='signum', description=None, className='org.apache.spark.sql.catalyst.expressions.Signum', isTemporary=True),\n",
       " Function(name='sin', description=None, className='org.apache.spark.sql.catalyst.expressions.Sin', isTemporary=True),\n",
       " Function(name='sinh', description=None, className='org.apache.spark.sql.catalyst.expressions.Sinh', isTemporary=True),\n",
       " Function(name='size', description=None, className='org.apache.spark.sql.catalyst.expressions.Size', isTemporary=True),\n",
       " Function(name='skewness', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Skewness', isTemporary=True),\n",
       " Function(name='slice', description=None, className='org.apache.spark.sql.catalyst.expressions.Slice', isTemporary=True),\n",
       " Function(name='smallint', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='sort_array', description=None, className='org.apache.spark.sql.catalyst.expressions.SortArray', isTemporary=True),\n",
       " Function(name='soundex', description=None, className='org.apache.spark.sql.catalyst.expressions.SoundEx', isTemporary=True),\n",
       " Function(name='space', description=None, className='org.apache.spark.sql.catalyst.expressions.StringSpace', isTemporary=True),\n",
       " Function(name='spark_partition_id', description=None, className='org.apache.spark.sql.catalyst.expressions.SparkPartitionID', isTemporary=True),\n",
       " Function(name='split', description=None, className='org.apache.spark.sql.catalyst.expressions.StringSplit', isTemporary=True),\n",
       " Function(name='sqrt', description=None, className='org.apache.spark.sql.catalyst.expressions.Sqrt', isTemporary=True),\n",
       " Function(name='stack', description=None, className='org.apache.spark.sql.catalyst.expressions.Stack', isTemporary=True),\n",
       " Function(name='std', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.StddevSamp', isTemporary=True),\n",
       " Function(name='stddev', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.StddevSamp', isTemporary=True),\n",
       " Function(name='stddev_pop', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.StddevPop', isTemporary=True),\n",
       " Function(name='stddev_samp', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.StddevSamp', isTemporary=True),\n",
       " Function(name='str_to_map', description=None, className='org.apache.spark.sql.catalyst.expressions.StringToMap', isTemporary=True),\n",
       " Function(name='string', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='struct', description=None, className='org.apache.spark.sql.catalyst.expressions.NamedStruct', isTemporary=True),\n",
       " Function(name='substr', description=None, className='org.apache.spark.sql.catalyst.expressions.Substring', isTemporary=True),\n",
       " Function(name='substring', description=None, className='org.apache.spark.sql.catalyst.expressions.Substring', isTemporary=True),\n",
       " Function(name='substring_index', description=None, className='org.apache.spark.sql.catalyst.expressions.SubstringIndex', isTemporary=True),\n",
       " Function(name='sum', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.Sum', isTemporary=True),\n",
       " Function(name='tan', description=None, className='org.apache.spark.sql.catalyst.expressions.Tan', isTemporary=True),\n",
       " Function(name='tanh', description=None, className='org.apache.spark.sql.catalyst.expressions.Tanh', isTemporary=True),\n",
       " Function(name='timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='tinyint', description=None, className='org.apache.spark.sql.catalyst.expressions.Cast', isTemporary=True),\n",
       " Function(name='to_date', description=None, className='org.apache.spark.sql.catalyst.expressions.ParseToDate', isTemporary=True),\n",
       " Function(name='to_json', description=None, className='org.apache.spark.sql.catalyst.expressions.StructsToJson', isTemporary=True),\n",
       " Function(name='to_timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.ParseToTimestamp', isTemporary=True),\n",
       " Function(name='to_unix_timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.ToUnixTimestamp', isTemporary=True),\n",
       " Function(name='to_utc_timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.ToUTCTimestamp', isTemporary=True),\n",
       " Function(name='transform', description=None, className='org.apache.spark.sql.catalyst.expressions.ArrayTransform', isTemporary=True),\n",
       " Function(name='translate', description=None, className='org.apache.spark.sql.catalyst.expressions.StringTranslate', isTemporary=True),\n",
       " Function(name='trim', description=None, className='org.apache.spark.sql.catalyst.expressions.StringTrim', isTemporary=True),\n",
       " Function(name='trunc', description=None, className='org.apache.spark.sql.catalyst.expressions.TruncDate', isTemporary=True),\n",
       " Function(name='ucase', description=None, className='org.apache.spark.sql.catalyst.expressions.Upper', isTemporary=True),\n",
       " Function(name='unbase64', description=None, className='org.apache.spark.sql.catalyst.expressions.UnBase64', isTemporary=True),\n",
       " Function(name='unhex', description=None, className='org.apache.spark.sql.catalyst.expressions.Unhex', isTemporary=True),\n",
       " Function(name='unix_timestamp', description=None, className='org.apache.spark.sql.catalyst.expressions.UnixTimestamp', isTemporary=True),\n",
       " Function(name='upper', description=None, className='org.apache.spark.sql.catalyst.expressions.Upper', isTemporary=True),\n",
       " Function(name='uuid', description=None, className='org.apache.spark.sql.catalyst.expressions.Uuid', isTemporary=True),\n",
       " Function(name='var_pop', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.VariancePop', isTemporary=True),\n",
       " Function(name='var_samp', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.VarianceSamp', isTemporary=True),\n",
       " Function(name='variance', description=None, className='org.apache.spark.sql.catalyst.expressions.aggregate.VarianceSamp', isTemporary=True),\n",
       " Function(name='weekday', description=None, className='org.apache.spark.sql.catalyst.expressions.WeekDay', isTemporary=True),\n",
       " Function(name='weekofyear', description=None, className='org.apache.spark.sql.catalyst.expressions.WeekOfYear', isTemporary=True),\n",
       " Function(name='when', description=None, className='org.apache.spark.sql.catalyst.expressions.CaseWhen', isTemporary=True),\n",
       " Function(name='window', description=None, className='org.apache.spark.sql.catalyst.expressions.TimeWindow', isTemporary=True),\n",
       " Function(name='xpath', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathList', isTemporary=True),\n",
       " Function(name='xpath_boolean', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathBoolean', isTemporary=True),\n",
       " Function(name='xpath_double', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathDouble', isTemporary=True),\n",
       " Function(name='xpath_float', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathFloat', isTemporary=True),\n",
       " Function(name='xpath_int', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathInt', isTemporary=True),\n",
       " Function(name='xpath_long', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathLong', isTemporary=True),\n",
       " Function(name='xpath_number', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathDouble', isTemporary=True),\n",
       " Function(name='xpath_short', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathShort', isTemporary=True),\n",
       " Function(name='xpath_string', description=None, className='org.apache.spark.sql.catalyst.expressions.xml.XPathString', isTemporary=True),\n",
       " Function(name='year', description=None, className='org.apache.spark.sql.catalyst.expressions.Year', isTemporary=True),\n",
       " Function(name='zip_with', description=None, className='org.apache.spark.sql.catalyst.expressions.ZipWith', isTemporary=True),\n",
       " Function(name='|', description=None, className='org.apache.spark.sql.catalyst.expressions.BitwiseOr', isTemporary=True),\n",
       " Function(name='~', description=None, className='org.apache.spark.sql.catalyst.expressions.BitwiseNot', isTemporary=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listFunctions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
