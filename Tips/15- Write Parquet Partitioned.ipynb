{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"test\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Hadoop \",\"Mumbai\",\"Lokesh\",\"M\",9000),\n",
    "      (\"Spark \",\"Banglore\",\"Rahul\",\"M\",7000),\n",
    "      (\"Scala \",\"Newyork\",\"Venkat\",\"M\",6000),\n",
    "      (\"Python \",\"Hydrabad\",\"Jasmin\",\"F\",7000),\n",
    "      (\"Java\",\"Dubai\",\"Pooja\",\"F\",12000)\n",
    "         ]\n",
    "columns = [\"coursename\",\"location\",\"name\",\"gender\",\"coursefee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------+---------+\n",
      "|coursename|location|  name|gender|coursefee|\n",
      "+----------+--------+------+------+---------+\n",
      "|   Hadoop |  Mumbai|Lokesh|     M|     9000|\n",
      "|    Spark |Banglore| Rahul|     M|     7000|\n",
      "|    Scala | Newyork|Venkat|     M|     6000|\n",
      "|   Python |Hydrabad|Jasmin|     F|     7000|\n",
      "|      Java|   Dubai| Pooja|     F|    12000|\n",
      "+----------+--------+------+------+---------+\n",
      "\n",
      "root\n",
      " |-- coursename: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- coursefee: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write DataFrame as parquet file\n",
    "df.write.mode(\"overwrite\").parquet(\"tmp/table/learner.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataFrame by reading that Parquet file again\n",
    "parquetDF = spark.read.parquet(\"tmp/table/learner.parquet\")\n",
    "#Create a Temporary view or table using Parquet DataFrame\n",
    "parquetDF.createOrReplaceTempView(\"ParquetTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------+---------+\n",
      "|coursename|location|  name|gender|coursefee|\n",
      "+----------+--------+------+------+---------+\n",
      "|   Hadoop |  Mumbai|Lokesh|     M|     9000|\n",
      "|    Spark |Banglore| Rahul|     M|     7000|\n",
      "|   Python |Hydrabad|Jasmin|     F|     7000|\n",
      "|      Java|   Dubai| Pooja|     F|    12000|\n",
      "+----------+--------+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select all the records where coursefee is more than 7000\n",
    "parquetSQLDF = spark.sql(\"select * from ParquetTable where coursefee >= 7000 \")\n",
    "parquetSQLDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data back, wich is partitioned by gender and coursefee\n",
    "df.write.mode(\"overwrite\").partitionBy(\"gender\",\"coursefee\").parquet(\"tmp/table/learner2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read back the partitioned data\n",
    "parquetDF2 = spark.read.parquet(\"tmp/table/learner2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan parquet [coursename#67,location#68,name#69,gender#70,coursefee#71] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/mnt/c/projects/notebook/CRT020/Tips/tmp/table/learner2.parquet], PartitionCount: 2, PartitionFilters: [isnotnull(gender#70), isnotnull(coursefee#71), (gender#70 = M), (coursefee#71 >= 7000)], PushedFilters: [], ReadSchema: struct<coursename:string,location:string,name:string>\n"
     ]
    }
   ],
   "source": [
    "#Create another temporary table from partitioned data\n",
    "parquetDF2.createOrReplaceTempView(\"ParquetTable2\")\n",
    "#Create DataFrame which contains only data where gender is Male and #Course Fee is more than 7000\n",
    "df2 = spark.sql(\"select * from ParquetTable2  where gender='M' and coursefee >= 7000\")\n",
    "#Check the explain plan\n",
    "df2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- coursename: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- coursefee: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[coursename: string, location: string, name: string, gender: string, coursefee: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------+---------+\n",
      "|coursename|location|  name|gender|coursefee|\n",
      "+----------+--------+------+------+---------+\n",
      "|   Hadoop |  Mumbai|Lokesh|     M|     9000|\n",
      "|    Spark |Banglore| Rahul|     M|     7000|\n",
      "+----------+--------+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the DataFrame Schema\n",
    "df2.printSchema()\n",
    "#Display DataFrame Contents\n",
    "display(df2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+---------+\n",
      "|coursename|location|  name|coursefee|\n",
      "+----------+--------+------+---------+\n",
      "|   Hadoop |  Mumbai|Lokesh|     9000|\n",
      "|    Spark |Banglore| Rahul|     7000|\n",
      "|    Scala | Newyork|Venkat|     6000|\n",
      "+----------+--------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read data from specific partitions\n",
    "df3 = spark.read.parquet(\"tmp/table/learner2.parquet/gender=M\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.write.format(\"parquet\").bucketBy(4, \"courseFee\").option(\"path\", \"tmp/bucket\").saveAsTable(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+---------+\n",
      "|coursename|location|  name|coursefee|\n",
      "+----------+--------+------+---------+\n",
      "|   Hadoop |  Mumbai|Lokesh|     9000|\n",
      "|    Spark |Banglore| Rahul|     7000|\n",
      "|    Scala | Newyork|Venkat|     6000|\n",
      "+----------+--------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"tmp/bucket\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(data):\n",
    "    print(data.name)\n",
    "\n",
    "df3.foreach(print_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(coursename='Hadoop ', location='Mumbai', name='Lokesh', coursefee=9000),\n",
       " Row(coursename='Spark ', location='Banglore', name='Rahul', coursefee=7000)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df3.take(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
